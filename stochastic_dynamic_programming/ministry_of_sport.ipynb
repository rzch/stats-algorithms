{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ministry of Sport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[The Riddler Classic 2018-11-09 puzzle](https://fivethirtyeight.com/features/what-are-the-odds-youd-already-have-my-number/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Suppose there are $T$ teams in the league, indexed by $\\left\\{1, \\dots, T\\right\\}$.\n",
    "\n",
    "Let $\\left(x_{k}, \\varsigma_{k}\\right)$ denote the state, which is the current scores and remaining schedule, respectively.\n",
    "\n",
    "Let $\\mathbb{U}_{k}\\left(\\varsigma_{k}\\right) = \\left\\{u_{1}, \\dots, u_{M}\\right\\} \\subseteq \\varsigma_{k}$ denote the set of possible matches which can be selected next, based on the remaining schedule (given by the next available match for each team). Each match is a pair $u = \\left(t_{1}, t_{2}\\right)$ for the teams that are facing each other.\n",
    "\n",
    "We can use [stochastic dynamic programming](https://en.wikipedia.org/wiki/Stochastic_dynamic_programming) to determine which match should be selected next, in order to minimise the expected number of matches before a season winner/tie is guaranteed (the mean is being used as a proxy for the median)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are at state $\\left(x_{k}, \\varsigma_{k}\\right)$, we can compute the action-state value function\n",
    "\\begin{equation}\n",
    "Q\\left(x_{k}, \\varsigma_{k}, u\\right) = 1 + p_{1}V_{1}^{*} + p_{2}V_{2}^{*} + p_{0}V_{0}^{*}\n",
    "\\end{equation}\n",
    "where $p_{1}$, $p_{2}$ and $p_{0}$ are the probabilities of win/lose/draw for team $t_{1}$ respectively. Hence\n",
    "\\begin{gather}\n",
    "p_{1} = \\dfrac{t_{1}}{t_{1} + t_{2} + 1} \\\\\n",
    "p_{2} = \\dfrac{t_{2}}{t_{1} + t_{2} + 1} \\\\\n",
    "p_{0} = \\dfrac{1}{t_{1} + t_{2} + 1} \n",
    "\\end{gather}\n",
    "and $V_{1}^{*}$, $V_{2}^{*}$, $V_{0}^{*}$ denote\n",
    "\\begin{gather}\n",
    "V_{1}^{*} = V^{*}\\left(x^{\\sharp}, \\varsigma^{-}\\right) \\\\\n",
    "V_{2}^{*} = V^{*}\\left(x^{\\flat}, \\varsigma^{-}\\right) \\\\\n",
    "V_{0}^{*} = V^{*}\\left(x^{\\natural}, \\varsigma^{-}\\right)\n",
    "\\end{gather}\n",
    "where\n",
    "* $V^{*}$ is the optimal value function\n",
    "* $x^{\\sharp}$ is the updated scores if match $u$ ends in a win for $t_{1}$\n",
    "* $x^{\\flat}$ is the updated scores if match $u$ ends in a win for $t_{2}$\n",
    "* $x^{\\natural}$ is the updated scores if match $u$ ends in a draw\n",
    "* $\\varsigma^{-}$ is the remaining schedule when match $u$ is removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus the recursive definition of the optimal value function when $\\left(x_{k}, \\varsigma_{k}\\right)$ does not have a guaranteed winner/tie is\n",
    "\\begin{equation}\n",
    "V^{*}\\left(x_{k}, \\varsigma_{k}\\right) = \\min_{u \\in \\mathbb{U}_{k}\\left(\\varsigma_{k}\\right)}Q\\left(x_{k}, \\varsigma_{k}, u\\right)\n",
    "\\end{equation}\n",
    "and the optimal policy is\n",
    "\\begin{equation}\n",
    "u^{*}\\left(x_{k}, \\varsigma_{k}\\right) = \\underset{u \\in \\mathbb{U}_{k}\\left(\\varsigma_{k}\\right)}{\\operatorname{argmin}}Q\\left(x_{k}, \\varsigma_{k}, u\\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there is a guaranteed season winner/tie, then $V^{*}\\left(x_{k}, \\varsigma_{k}\\right) = 0$. The following conditions must be met in order for a winner to be guaranteed:\n",
    "* If there is only one leader, then every other team must not be able to catch up, even if they win all their matches and the leader gains no points for the remainder of the season.\n",
    "* If there is more than one leader (tied), then each of the the leaders must not have any matches remaining (so the balance of the tie cannot be tipped), and every other team must not be able to catch up, even if they win all their matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random selection\n",
      "Mean: 5.544\n",
      "Median: 6.0\n",
      "Mean-optimal policy\n",
      "Mean: 5.079\n",
      "Median: 5.0\n"
     ]
    }
   ],
   "source": [
    "import ministry_of_sport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With $T = 4$ teams, the optimal policy yields a median of $5$ matches, whereas a policy of just selecting the next match on the schedule yields a median of $6$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
